<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2015-11-26 Thu 00:47 -->
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="viewport" content="width=device-width, initial-scale=1" />
<title>kNN 分类器和 K-D 树，LSH</title>
<meta  name="generator" content="Org-mode" />
<meta  name="author" content="Spinpx" />
<link rel="stylesheet" type="text/css" href="http://spinpx.com/org.css"/>
</head>
<body>
<div id="preamble" class="status">
<div class = "nav">
    <ul>
    <li><a class = "logo" href="/index.html">SPinPx</a><li>
	<li><a href="/posts.html"> Posts </a></li>
	<li><a href="/notes.html"> Notes </a></li>
	<li><a href="/about.html"> About </a></li>
    </ul>
</div>
</div>
<div id="content">
<h1 class="title">kNN 分类器和 K-D 树，LSH</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgheadline1">kNN 分类器</a></li>
<li><a href="#orgheadline2">为什么 kNN 那么慢？</a></li>
<li><a href="#orgheadline3">k-D 树（k-demension tree）</a>
<ul>
<li><a href="#orgheadline4">原理</a></li>
<li><a href="#orgheadline5">构造一棵 k-d 树</a></li>
<li><a href="#orgheadline6">最近邻搜索</a>
<ul>
<li><a href="#orgheadline7">关于 hyperrectangle</a></li>
<li><a href="#orgheadline8">伪代码</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgheadline9">LSH（locality-sensitive hash）</a>
<ul>
<li><a href="#orgheadline10">原理</a></li>
</ul>
</li>
<li><a href="#orgheadline11">其他方法</a></li>
<li><a href="#orgheadline12">参考资料</a></li>
</ul>
</div>
</div>
<div id="outline-container-orgheadline1" class="outline-2">
<h2 id="orgheadline1">kNN 分类器</h2>
<div class="outline-text-2" id="text-orgheadline1">
<ul class="org-ul">
<li>kNN（k-Nearest-Neighbors）分类器是一种简单基础的分类方法，当我们对数据分布了解很少时，kNN 通常是一个不错的选择。</li>
<li>kNN 分类器的诞生是为了解决没有可靠的参数估计和盖里密度请快下的判别分析。</li>
<li>所需要的一些工作：特征提取，特征转换，距离方法的选择</li>
<li>k 近邻算法是一种用来分类(classification)的非参数(non-parametric)方法.</li>
<li>优点
<ol class="org-ol">
<li>训练快</li>
<li>可以学习复杂的目标</li>
<li>不会丢失信息</li>
</ol></li>
<li>缺点
<ol class="org-ol">
<li>查询慢</li>
<li>容易受冗余信息影响</li>
</ol></li>
</ul>
</div>
</div>

<div id="outline-container-orgheadline2" class="outline-2">
<h2 id="orgheadline2">为什么 kNN 那么慢？</h2>
<div class="outline-text-2" id="text-orgheadline2">
<ul class="org-ul">
<li>假设这是一个简单的 kNN 分类器，由 n 个训练集，d 维空间。</li>
<li>对于测试（查询）操作需要 n 次比较，每次比较都得花费 d 维的计算，即 O(Nd).</li>
<li>对于数据量大，维度高时的情况，效率太差。因此我们需要改进 kNN 算法，使它变得更快。从查询操作的时间复杂度出发，它与 N，d 成正比，因此，如果我们可以降低数据的数量活维度，即可提高查询效率。</li>
<li>对于维度来说，如果要降低维度，我们需要改进数据特征的选择，选择简单的数据特征。PCA（Principal component analysis），LDA（Linear discriminant analysis）。</li>
<li>对于降低数据量 N，我们不可能在数据量足够多的情况下选择少量数据来学习，因为更多的数据意味着更高的准确性。但是，我们可以从另外的角度出发，我们可以通过一些方法去掉那些不可能是 k 最近邻的 点，降低我们在一次查询操作中需要比较的点的个数。那么，现在的问题变成了，在所有的数据点中，我们在一次查询操作中，要选择哪些点来比较。</li>
<li>合适的数据结构和算法可以让我们更好的解决这一问题。KNN 的遍历算法，ANN（Approximate Nearest Neighbor），NN search。</li>
</ul>
</div>
</div>

<div id="outline-container-orgheadline3" class="outline-2">
<h2 id="orgheadline3">k-D 树（k-demension tree）</h2>
<div class="outline-text-2" id="text-orgheadline3">
<ul class="org-ul">
<li>时间复杂度：O(dlogN)</li>
<li>特点：局限于低维（当 d&lt;&lt; n 会丢失邻居点），高维（20 维以上）效率就很差</li>
</ul>
</div>
<div id="outline-container-orgheadline4" class="outline-3">
<h3 id="orgheadline4">原理</h3>
<div class="outline-text-3" id="text-orgheadline4">
<ul class="org-ul">
<li>k-D 树是一种用来存储 k 维空间上有限个点的数据结构。它在 1977 年被 J.Bentley 详细论证，并因为在 1987 年 S.Omohundro 的研究中利用该技术增快了神经网络的学习而被大力推荐。</li>
<li>k-D 树是一种二叉树，每个节点的结构大概是这样的</li>
</ul>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">Name</td>
<td class="org-left">Type</td>
<td class="org-left">descroption</td>
</tr>

<tr>
<td class="org-left">dom-elt</td>
<td class="org-left">domain-vector</td>
<td class="org-left">A point from k<sub>d</sub>-d space</td>
</tr>

<tr>
<td class="org-left">range-elt</td>
<td class="org-left">range-vector</td>
<td class="org-left">A point from k<sub>r</sub>-d space</td>
</tr>

<tr>
<td class="org-left">split</td>
<td class="org-left">integer</td>
<td class="org-left">The splitting dimension</td>
</tr>

<tr>
<td class="org-left">left</td>
<td class="org-left">kd-tree</td>
<td class="org-left">the left of the splitting plane</td>
</tr>

<tr>
<td class="org-left">right</td>
<td class="org-left">kd-tree</td>
<td class="org-left">the right of the splitting plane</td>
</tr>
</tbody>
</table>

<ul class="org-ul">
<li>一棵 k-D 树代表了所有的样本集（exemplar-set）E，每个节点代表一个样本。样本的 domain-vector 用 dom-elt 表示，range-vector 用 range-elt 表示。我们用 dom-elt 来充当节点的索引，它根据节点的分割的超平面将一个空间分为两个子空间，从而使一棵 kD 树的左子树代表一个空间，右子树代表另外一个空间。超平面是一个通过 dom-elt 的一个平面，并且与 split 所指定的方向（维）呈正交关系。</li>
<li>因此，如果我们指定 split 为 i，那么 k-d 树上某个点的左子树上点的 dom-elt 的第 i 个元素必然小于该点的第 i 个元素。如果一个节点没有孩子，那么它就没有（不需要）超平面。split 由样本集中维度的方差大小确定，选择方差最大的一维。</li>
<li>举个例子</li>
</ul>

<div class="figure">
<p><img src="img/a1.png" alt="a1.png" />
</p>
</div>

<ul class="org-ul">
<li>根节点（2，5）在以第 2 个维（y）平行的平面 划分出了 2 个子平面。点（3，8）的第 2 个维上的值 8 大于 5，所以它在根节点的右子树上，即右平面上。</li>

<li>因此，一棵 kd 树实际上是样本集的映射。他们存在如下关系：

<ol class="org-ol">
<li>sets(empty) :=&gt; empty</li>

<li>sets(&lt;d,r,-,empty,empty) :=&gt;{(d,r)}</li>

<li>sets(&lt;d,r,split,tree<sub>left</sub>,tree<sub>right</sub>) :=&gt;sets(tree<sub>left</sub>) u {(d,r)} u sets(tree<sub>right</sub>)</li>
</ol></li>
</ul>
</div>
</div>

<div id="outline-container-orgheadline5" class="outline-3">
<h3 id="orgheadline5">构造一棵 k-d 树</h3>
<div class="outline-text-3" id="text-orgheadline5">
<ul class="org-ul">
<li>输入：sets，样本集</li>
<li>输出：一棵新鲜的 k-d 树</li>
<li>伪代码：</li>
</ul>
<div class="org-src-container">

<pre class="src src-ruby"><span style="color: #2aa1ae; background-color: #292e34;">#</span><span style="color: #2aa1ae; background-color: #292e34;">def KDTtree(sets)</span>
<span style="color: #237fbf; font-weight: bold;">return</span> empty <span style="color: #237fbf; font-weight: bold;">if</span> sets.empty? 
<span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">choose_set is the midest set in sets sorted by the sp , spilt is the choose plane's number</span>
<span style="color: #2f96dc;">[</span>choose_set,split<span style="color: #2f96dc;">]</span> = pivot_choosing procedure<span style="color: #2f96dc;">(</span>sets<span style="color: #2f96dc;">)</span>
d = choose_set.dom_elt
r = choose_set.range_elt
new_sets = sets - choose_set
left_sets = new Set<span style="color: #2f96dc;">()</span>
right_sets = new Set<span style="color: #2f96dc;">()</span>
new_sets.each <span style="color: #237fbf; font-weight: bold;">do</span> |s|
  <span style="color: #237fbf; font-weight: bold;">if</span> s.dom_elt<span style="color: #2f96dc;">[</span>split<span style="color: #2f96dc;">]</span> &lt;= d<span style="color: #2f96dc;">[</span>split<span style="color: #2f96dc;">]</span> <span style="color: #237fbf; font-weight: bold;">then</span>
    left_sets.push<span style="color: #2f96dc;">(</span>s<span style="color: #2f96dc;">)</span>  
  <span style="color: #237fbf; font-weight: bold;">else</span> 
    right_sets.push<span style="color: #2f96dc;">(</span>s<span style="color: #2f96dc;">)</span>
  <span style="color: #237fbf; font-weight: bold;">end</span> 
<span style="color: #237fbf; font-weight: bold;">end</span>
kdleft = KDTree<span style="color: #2f96dc;">(</span>left_sets<span style="color: #2f96dc;">)</span>
kdright = KDTree<span style="color: #2f96dc;">(</span>right_sets<span style="color: #2f96dc;">)</span>
<span style="color: #237fbf; font-weight: bold;">return</span> <span style="color: #2f96dc;">[</span>d,r,split,kdleft,kdright<span style="color: #2f96dc;">]</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-orgheadline6" class="outline-3">
<h3 id="orgheadline6">最近邻搜索</h3>
<div class="outline-text-3" id="text-orgheadline6">
<ul class="org-ul">
<li>还是以 3.1 中的图为例子，假设我们已经为它构造好了 KD 树，则有</li>
</ul>

<div class="figure">
<p><img src="img/layer1.png" alt="layer1.png" />
</p>
</div>
<ul class="org-ul">
<li>假设我们要寻找的点是[6.5,4.8]</li>
<li>根据 kd 树，我们先找到该点所在区域的叶子节点[8,4]。然而该节点上的值不一定是和目标点最近的，但是它是所有点中，可能性最大的，并且最近的点一定在该区域附近。</li>
<li>我们需要找到比叶子节点和目标节点之间的距离更小的节点。</li>
<li>因为这个点肯定在该叶子节点附近，所以我们先回溯到该叶子节点的父节点[5,3]。</li>
<li>我们需要查看父节点或它的其他儿子是否会更近，很明显[2,2]是不可能的。</li>
<li>于是继续向上递归，直到找到满足的节点。</li>
</ul>

<div class="figure">
<p><img src="img/layer2.png" alt="layer2.png" />
</p>
</div>
</div>

<div id="outline-container-orgheadline7" class="outline-4">
<h4 id="orgheadline7">关于 hyperrectangle</h4>
<div class="outline-text-4" id="text-orgheadline7">
<ul class="org-ul">
<li>由两个数组组成，一个是它的最小坐标，另一个是它的最大坐标。</li>
<li>cut<sub>rect</sub> 方法将根据 split 和 domain 得到两个新的 hyperrectangle.</li>
<li>而 intersect<sub>rect</sub> 方法将根据 target 和 dist-sqd 来判断最近点是否可能在该矩阵内，具体原理如下：</li>
<li>hyperrectangle 是一个矩阵 hr，为了检查该矩阵是否和一个圆心为 p，半径为 r 的 hypersphere 相交，我们找到 hr 中离 t 最近的点 p。若用 hr<sub>i</sub><sup>min</sup>表示 i 维上 hr 的最小值，hr<sub>i</sub><sub>max</sub>为最大值，那么可以得到 i 维上的最小值 p<sub>i</sub> = :

<ul class="org-ul">
<li>hr<sub>i</sub><sup>min</sup>, if t<sub>i</sub> &lt;= hr<sub>i</sub><sup>min</sup></li>
<li>t<sub>i</sub>,  if hr<sub>i</sub><sup>min</sup> &lt; t<sub>i</sub> &lt; hr<sub>i</sub><sup>max</sup></li>
<li>hr<sub>i</sub><sup>min</sup>, if t<sub>i</sub> &gt;= hr<sub>i</sub><sup>max</sup></li>
</ul></li>

<li>两者相交当且仅当 p,t 间的距离小于等于 r</li>
</ul>
</div>
</div>

<div id="outline-container-orgheadline8" class="outline-4">
<h4 id="orgheadline8">伪代码</h4>
<div class="outline-text-4" id="text-orgheadline8">
<ul class="org-ul">
<li>输入：
<ul class="org-ul">
<li>kd:  一棵 kd 树(KDTree)</li>
<li>target: 目标点（domain vector）</li>
<li>hr : hyperrectangle 矩阵空间</li>
<li>max-dist-sqd: float 距离</li>
</ul></li>
<li>输出：
<ul class="org-ul">
<li>nearest: 样本点</li>
<li>dist-sqd: float 距离</li>
</ul></li>
</ul>
<div class="org-src-container">

<pre class="src src-ruby"><span style="color: #2aa1ae; background-color: #292e34;">#</span><span style="color: #2aa1ae; background-color: #292e34;">def ANN_kd(kd,target,hr,max_dist_sqd)</span>
dist = infinity <span style="color: #237fbf; font-weight: bold;">if</span> kd.empty?
s = kd.split
pivot = kd.dom_elt
<span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">hr is cut into two sub-hyperrectangles by the pland of s and pivot</span>
<span style="color: #2f96dc;">[</span>left_hr,right_hr<span style="color: #2f96dc;">]</span> = cut_rect<span style="color: #2f96dc;">(</span>hr,s,pivot<span style="color: #2f96dc;">)</span>
<span style="color: #237fbf; font-weight: bold;">if</span> target<span style="color: #2f96dc;">[</span>s<span style="color: #2f96dc;">]</span> &lt;= pivot<span style="color: #2f96dc;">[</span>s<span style="color: #2f96dc;">]</span> <span style="color: #237fbf; font-weight: bold;">then</span>
  nearer_kd = kd.kdleft
  nearer_hr = left_hr
  further_kd = kd.kdright
  further_ht = right_hr
<span style="color: #237fbf; font-weight: bold;">else</span> 
  nearer_kd = kd.kdright
  nearer_hr = right_hr
  further_kd = kd.kdleft
  further_ht = left_hr
<span style="color: #237fbf; font-weight: bold;">end</span>
<span style="color: #2f96dc;">[</span>nearer_kd,dist_sqd<span style="color: #2f96dc;">]</span> = ANN_kd<span style="color: #2f96dc;">(</span>nearer_kd,target,nearer_hr,max_dist_sqd<span style="color: #2f96dc;">)</span>
max_dist_sql = max_dist_sqd &gt; dist_sqd? dist_sqd : max_dist_sqd
<span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">xxx</span>
<span style="color: #237fbf; font-weight: bold;">if</span> intersect_rect<span style="color: #2f96dc;">(</span>further_hr,target,max_dist_sqd<span style="color: #2f96dc;">)</span> <span style="color: #237fbf; font-weight: bold;">then</span>
  dist_tmp = <span style="color: #ce537a; font-weight: bold;">Math</span>.sqrt<span style="color: #2f96dc;">(</span>pivot - target<span style="color: #2f96dc;">)</span>
  <span style="color: #237fbf; font-weight: bold;">if</span> dist_tmp &lt; dist_sqd <span style="color: #237fbf; font-weight: bold;">then</span>
    nearest = <span style="color: #2f96dc;">[</span>kd.pivot,kd.range_elt<span style="color: #2f96dc;">]</span>
    max_dist_sqd = dist_sqd = dist_tmp
    <span style="color: #2f96dc;">[</span>temp_nearest,temp_dist_sqd<span style="color: #2f96dc;">]</span> = ANN_kd<span style="color: #2f96dc;">(</span>further_kd,target,further_hr,max_dist_sqd<span style="color: #2f96dc;">)</span>
    <span style="color: #237fbf; font-weight: bold;">if</span> temp_dist_sqd &lt;dist_sqd <span style="color: #237fbf; font-weight: bold;">then</span>
      nearest = temp_nearest 
      dist_sqd = temp_dist_sqd
    <span style="color: #237fbf; font-weight: bold;">end</span>
  <span style="color: #237fbf; font-weight: bold;">end</span> 
<span style="color: #237fbf; font-weight: bold;">end</span>
</pre>
</div>
</div>
</div>
</div>
</div>
<div id="outline-container-orgheadline9" class="outline-2">
<h2 id="orgheadline9">LSH（locality-sensitive hash）</h2>
<div class="outline-text-2" id="text-orgheadline9">
<ul class="org-ul">
<li>时间复杂度：O(N)</li>
<li>特点：适用于高维特征，构建简单，查询速度快，和数据大小线性关系。</li>
</ul>
</div>
<div id="outline-container-orgheadline10" class="outline-3">
<h3 id="orgheadline10">原理</h3>
<div class="outline-text-3" id="text-orgheadline10">
<ul class="org-ul">
<li>将数据点高维空间上的点映射到不同的桶（bin）上，但是不像传统的哈希，局部敏感哈希将处在附近的点放到同一个桶中。也就是说，如果我们对原始数据进行一些 hash 映射后，我们希望原先相邻的两个数据能够被 hash 到相同的桶内，具有相同的桶号。</li>
<li>为了判别什么情况下是近邻，应该在一个桶内，我们需要找到一些特别的 hash 函数，使得经过它们的哈希映射变换后，原始空间中相邻的数据落入相同的桶内。</li>
<li>当数据样本存储在这种类型的 hash 结构里时，当我们需要查询一个点的最近邻，只需对该点进行 hash 映射，根据映射得到的桶的编号，将该点与桶里面的每一个点进行线性匹配即可。因此查询的时间复杂度为 O（N）。</li>
</ul>
</div>
</div>
</div>


<div id="outline-container-orgheadline11" class="outline-2">
<h2 id="orgheadline11">其他方法</h2>
<div class="outline-text-2" id="text-orgheadline11">
<ul class="org-ul">
<li><a href="http://en.wikipedia.org/wiki/Inverted_index">inverted index</a></li>
<li><a href="http://hunch.net/~jl/projects/cover_tree/cover_tree.html">cover tree</a></li>
<li><a href="http://stevehanov.ca/blog/index.php/?id=130">vp tree</a></li>
</ul>
</div>
</div>

<div id="outline-container-orgheadline12" class="outline-2">
<h2 id="orgheadline12">参考资料</h2>
<div class="outline-text-2" id="text-orgheadline12">
<ul class="org-ul">
<li>「课件」</li>

<li><a href="http://www.scholarpedia.org/article/K-nearest_neighbor">kNN wikipedia</a></li>

<li><a href="http://stackoverflow.com/questions/5751114/nearest-neighbors-in-high-dimensional-data">Nearest neighbors in high-dimensional data?</a></li>

<li><a href="http://en.wikipedia.org/wiki/K-d_tree">k-d tree -wikipedia</a></li>
<li><a href="http://www.cnblogs.com/eyeszjwang/articles/2429382.html">k-d tree 算法</a></li>
<li>「an inductory tutorial to k-d tree」Andrew W.Moore</li>

<li><a href="http://blog.csdn.net/icvpr/article/details/12342159">局部敏感哈希(Locality-Sensitive Hashing, LSH)方法介绍</a></li>
</ul>
</div>
</div>
</div>
<div id="postamble" class="status">
<p id="update">Last Updated : 2015-11-26 Thu 00:47 , Created by <a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.5.1 (<a href="http://orgmode.org">Org</a> mode 8.3.2)</p>
</div>
</body>
</html>
